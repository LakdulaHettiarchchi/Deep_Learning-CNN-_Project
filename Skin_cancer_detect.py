# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TeIh0-HuaAuyFqXyhgBWbjPOCgh0ECcA
"""

!pip install -q keras

import keras

from keras.layers import Input, Lambda, Dense, Flatten, MaxPooling2D,Conv2D
from keras.models import Model, Sequential
from keras.applications.vgg16 import VGG16
# from keras.applications.vgg19 import VGG19
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing.image import image
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
import glob
from keras.layers.normalization import batch_normalization
import os
import seaborn as sns
import cv2
# from keras.models import sequential
# from keras.layers.normalization import BatchNormalization
# from keras.layers.normalization import BatchNormalization
from tensorflow.keras.layers import BatchNormalization

from google.colab import drive
drive.mount('/content/drive/')

!wget /content/drive/MyDrive/archive_4.zip

!unzip /content/drive/MyDrive/archive_4.zip

print(os.listdir('/content/train'))

print(os.listdir('/content/test'))

IMAGE_SIZE = 224

train_images = []
train_labels = []

for directory_path in glob.glob("/content/train/*"):
  label = directory_path.split("\\")[-1]
  print(label)
  for img_path in glob.glob(os.path.join(directory_path, '*.jpg')):
    print(img_path)
    img = cv2.imread(img_path, cv2.IMREAD_COLOR)
    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    train_images.append(img)
    train_labels.append(label)

train_images = np.array(train_images)
train_labels = np.array(train_labels)

test_images = []
test_labels = []

for directory_path in glob.glob("/content/test/*"):
  T_label = directory_path.split("\\")[-1]
  print(T_label)
  for img_path in glob.glob(os.path.join(directory_path, '*.jpg')):
    print(img_path)
    img = cv2.imread(img_path, cv2.IMREAD_COLOR)
    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    test_images.append(img)
    test_labels.append(T_label)

test_images = np.array(test_images)
test_labels = np.array(test_labels)

#Encode Labels from text to integer
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(test_labels)
test_lebels_encoded = le.transform(test_labels)
# print(test_lebels_encoded)
le.fit(train_labels)
train_labels_encoded = le.transform(train_labels)
print(train_labels_encoded)

#split dtat into test and train data set 
x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_lebels_encoded

#Normalize pixael values to between 0 and 1
x_train = x_train / 225.0
x_test  = x_test / 225.0

#One hot encoding
from tensorflow.keras.utils import to_categorical
y_train_one_hot = to_categorical(y_train)
y_test_one_hot  = to_categorical(y_test)
# print(y_test_one_hot)

activation = 'relu'

feature_extractor = Sequential()
feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))
feature_extractor.add(BatchNormalization())

feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
feature_extractor.add(BatchNormalization())
feature_extractor.add(MaxPooling2D())

feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
feature_extractor.add(BatchNormalization())

feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))
feature_extractor.add(BatchNormalization())
feature_extractor.add(MaxPooling2D())

feature_extractor.add(Flatten())

#add Layers for deep learning
x= feature_extractor.output
x= Dense(128, activation =activation, kernel_initializer='he_uniform')(x)
prediction_layer = Dense(2, activation = 'softmax')(x)

cnn_model = Model(inputs =feature_extractor.input, outputs = prediction_layer)
cnn_model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy', metrics = ['accuracy'])
print(cnn_model.summary())

history = cnn_model.fit(x_train, y_train_one_hot, epochs=10, validation_data = (x_test, y_test_one_hot))

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
plt.plot(epochs, accuracy, 'y', label='Training acc')
plt.plot(epochs, val_accuracy, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

prediction_NN = cnn_model.predict(x_test)
prediction_NN = np.argmax(prediction_NN, axis=-1)
prediction_NN = le.inverse_transform(prediction_NN)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_labels, prediction_NN)
print(cm)
# sns.heatmap(cm, annot=True)

n= np.random.randint(0, x_test.shape[0])
img = x_test[n]
plt.imshow(img)
input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)
prediction = np.argmax(cnn_model.predict(input_img))  #argmax to convert categorical back to original
prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name
print("The prediction for this image is: ", prediction)
print("The actual label for this image is: ", test_labels[n])

X_for_RF = feature_extractor.predict(x_train)